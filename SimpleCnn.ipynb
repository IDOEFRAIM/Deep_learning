{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6c06dc-7d16-4291-88cc-8d10824b1623",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D,Flatten,MaxPool2D,Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551db373-78f0-4668-aaa2-183d65b74979",
   "metadata": {},
   "source": [
    "<h1>We load and preprocess our data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd070dc-7ec8-418a-9979-d70145e7cc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,y_train), (X_test ,y_test) = mnist.load_data()\n",
    "\n",
    "#we normalize our data\n",
    "X_train = np.reshape(X_train,(-1,28,28,1)).astype('float32') / 255.0\n",
    "X_test = np.reshape(X_test,(-1,28,28,1)).astype('float32') / 255.0\n",
    "\n",
    "#we categorize it\n",
    "y_train = to_categorical(y_train,10)\n",
    "y_test = to_categorical(y_test,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96267304-cbb5-4f78-a44d-21e09d42a52b",
   "metadata": {},
   "source": [
    "<h1>We set our first model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15ac84e-9071-4ada-a0ba-9ec90236d74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    #we set the expected input\n",
    "    Input((28,28,1)),\n",
    "\n",
    "    #We implement the first convolutionnal layers.Wenhave 32 kernel of dimension 3,3.It returns 32 features maps of dimensions 26,26,1. Each filter detects a pattern ,it can be borders\n",
    "    #After we use an activation function relu for getting non linearity. Without it , we only work with linearity. Relu allows us to implement no linearity tasks such as pattern detection\n",
    "    Conv2D(32, kernel_size=(3,3),activation='relu'),\n",
    "\n",
    "    #MaxPool layers decreses the size of features maps and allows us to have a better pattern detection\n",
    "    MaxPool2D(pool_size=(2,2)),\n",
    "\n",
    "    Conv2D(64,kernel_size=(3,3),activation='relu',padding='same'),\n",
    "    MaxPool2D(pool_size=(2,2)),\n",
    "\n",
    "    #we flatten the feature map\n",
    "    Flatten(),\n",
    "    Dense(128,activation='relu'),\n",
    "\n",
    "    #we use  softmax for calculating probabilities. As soon as we expect 10 value (0-9),we set the first parameter to 10\n",
    "    Dense(10,activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756fbec6-8210-4b60-bca3-e0126315c675",
   "metadata": {},
   "source": [
    "*Lets compile our model*\n",
    "''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42947c00-f4b9-4dae-86c3-6f6ae59d907b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a109a176-755d-4a5a-919e-3031195e9beb",
   "metadata": {},
   "source": [
    "*We can now train \n",
    "our model*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a40aa0-b034-400c-a778-3b6bee12d848",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc21d550-a712-42af-b645-f29b019b5cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train,y_train,epochs=5,batch_size=64,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39572040-844c-4369-90b3-1ebf3ef59075",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Our loss',history.history['loss'])\n",
    "print('Our accuracy',history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8486bbfb-0a3e-4c46-a041-cf089a1768f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "*Lets visualize the performance*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a0be0e-cf27-4367-9e95-ae68ba50387c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'],label='train loss')\n",
    "plt.plot(history.history['val_loss'],label='validation loss')\n",
    "plt.title('The fluctuation of the precision')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea635414-62e0-4336-a9bd-484286dd07f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'],label='train accuracy')\n",
    "plt.plot(history.history['val_accuracy'],label='validation accuracy')\n",
    "plt.title('The fluctuation of the accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
